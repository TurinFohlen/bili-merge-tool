#!/usr/bin/env python3
"""
ç»Ÿä¸€æ‰“åŒ…åˆ†ç‰‡ä¼ è¾“ç»„ä»¶ v1.2.3 - å·¥ä¸šçº§ç¨³å®šç‰ˆ
ä¸»è¦ç‰¹æ€§ï¼š
  1. å—å¤§å° (bs) ä¸é‡å é‡ (overlap) ä¸¥æ ¼å¯¹é½ä¸º 1024 å­—èŠ‚ã€‚
  2. ä½¿ç”¨ iflag=fullblock å¼ºåˆ¶ dd è¯»å–å®Œæ•´å—ï¼Œé˜²æ­¢ç®¡é“æå‰æˆªæ–­ã€‚
  3. é‡‡ç”¨ (actual_size + bs - 1) // bs å‘ä¸Šå–æ•´è®¡ç®—å—æ•°ï¼Œç¡®ä¿æœ«å°¾æ•°æ®ä¸ä¸¢å¤±ã€‚
  4. å¢åŠ è¶…æ—¶è‡³ 300sï¼Œå¼ºåŒ– MD5 æ ¡éªŒå¤±è´¥åçš„é˜»æ–­æœºåˆ¶ã€‚
"""
import os
import tarfile
import hashlib
import base64
import tempfile
import shutil
import time
from typing import Optional, Tuple
from registry import registry

@registry.register("pack.transfer", "service", "download_and_extract(uid, c_folder, cleanup) -> bool")
class PackTransfer:
    def __init__(self):
        self.bili_root = "/storage/emulated/0/Android/data/tv.danmaku.bili/download"
        self.remote_tmp = "/data/local/tmp"
        self.local_cache = None
        self.chunk_size = 10 * 1024 * 1024  # 10MB
        self.overlap = 1024                 # 1KB é‡å åŒºåŸŸ
        self.max_retries = 3
        self.retry_delay = 2
        self.rish_exec = None

    def set_rish_executor(self, rish_exec):
        self.rish_exec = rish_exec

    def set_local_cache(self, path: str):
        self.local_cache = path
        os.makedirs(path, exist_ok=True)

    def check_local_cache(self, uid: str, c_folder: str) -> bool:
        if not self.local_cache:
            return False
        local_path = os.path.join(self.local_cache, uid, c_folder)
        if not os.path.exists(local_path):
            return False
        entry_json = os.path.join(local_path, "entry.json")
        if os.path.exists(entry_json) and os.path.getsize(entry_json) > 0:
            print(f"  âœ… æœ¬åœ°ç¼“å­˜å·²å­˜åœ¨: {uid}/{c_folder}")
            return True
        for root, dirs, files in os.walk(local_path):
            for f in files:
                if f.endswith(('.m4s', '.mp4', '.blv', '.m4a')):
                    print(f"  âœ… æœ¬åœ°ç¼“å­˜å·²å­˜åœ¨ï¼ˆåª’ä½“æ–‡ä»¶ç¡®è®¤ï¼‰")
                    return True
        return False

    def _remote_pack(self, uid: str, c_folder: str) -> Tuple[str, int]:
        if not self.rish_exec:
            raise RuntimeError("rish_exec æœªæ³¨å…¥")
        source_dir = f"{self.bili_root}/{uid}/{c_folder}"
        tar_name = f"{uid}_{c_folder}.tar"
        remote_tar = f"{self.remote_tmp}/{tar_name}"
        print(f"  ğŸ“¦ è¿œç¨‹æ‰“åŒ…: {c_folder}")

        rc, _, _ = self.rish_exec(f"test -d '{source_dir}'", check=False, timeout=10)
        if rc != 0:
            raise FileNotFoundError(f"è¿œç¨‹æºç›®å½•ä¸å­˜åœ¨: {source_dir}")

        self.rish_exec(f"rm -f '{remote_tar}'", check=False, timeout=10)

        parent_dir = f"{self.bili_root}/{uid}"
        cmd = f"cd '{parent_dir}' && tar -cf '{remote_tar}' '{c_folder}'"
        try:
            rc, out, err = self.rish_exec(cmd, timeout=300)
            if rc != 0:
                raise RuntimeError(f"æ‰“åŒ…å¤±è´¥: {err[:200]}")
        except Exception as e:
            raise RuntimeError(f"æ‰“åŒ…å¼‚å¸¸: {e}")

        file_size = None
        for attempt in range(3):
            try:
                _, size_str, _ = self.rish_exec(f"stat -c %s '{remote_tar}'", timeout=10)
                size_str = size_str.strip()
                if size_str:
                    file_size = int(size_str)
                    break
            except:
                pass
            time.sleep(2 * (2 ** attempt))

        if file_size is None:
            raise RuntimeError("æ— æ³•è·å–è¿œç¨‹æ‰“åŒ…æ–‡ä»¶å¤§å°")

        print(f"  âœ… æ‰“åŒ…å®Œæˆ: {file_size // 1024 // 1024}MB")
        return remote_tar, file_size

    def _download_chunks_overlap(self, remote_tar: str, file_size: int, local_tar: str) -> bool:
        if not self.rish_exec:
            raise RuntimeError("rish_exec æœªæ³¨å…¥")

        chunk_size = self.chunk_size
        overlap = self.overlap
        bs = 1024  # åŸºç¡€å—å•ä½ 1KB
        n_chunks = (file_size + (chunk_size - overlap) - 1) // (chunk_size - overlap)
        if n_chunks == 0: n_chunks = 1
        
        print(f"  ğŸ“¥ ä¸‹è½½è§„åˆ’: {n_chunks} ç‰‡, å—å¤§å° {bs}B, å‘ä¸Šå–æ•´æ¨¡å¼")

        temp_dir = tempfile.mkdtemp(prefix="bili_pack_")
        part_files = []

        try:
            for i in range(n_chunks):
                # è®¡ç®—åˆ†ç‰‡å­—èŠ‚èŒƒå›´
                start = i * (chunk_size - overlap)
                if start < 0: start = 0
                end = min(start + chunk_size, file_size)
                actual_size = end - start

                # å‘ä¸Šå–æ•´è®¡ç®—å—æ•°
                skip_blocks = start // bs
                count_blocks = (actual_size + bs - 1) // bs

                part_file = os.path.join(temp_dir, f"part_{i:03d}")
                success = False

                for retry in range(self.max_retries + 3):
                    try:
                        # iflag=fullblock æ˜¯é˜²æ­¢æ•°æ®æˆªæ–­çš„æ ¸å¿ƒ
                        cmd = f"dd if='{remote_tar}' bs={bs} skip={skip_blocks} count={count_blocks} iflag=fullblock 2>/dev/null | base64 -w 0"
                        rc, b64_data, _ = self.rish_exec(cmd, check=False, timeout=300)

                        if rc != 0 or not b64_data.strip():
                            time.sleep(self.retry_delay * (2 ** retry))
                            continue

                        b64_data = b64_data.strip()
                        missing_padding = len(b64_data) % 4
                        if missing_padding:
                            b64_data += '=' * (4 - missing_padding)

                        data = base64.b64decode(b64_data)
                        if len(data) > actual_size:
                            data = data[:actual_size]

                        # ä¸¥æ ¼é•¿åº¦æ ¡éªŒ
                        if len(data) < actual_size:
                            print(f"  âš ï¸ åˆ†ç‰‡ {i+1} é•¿åº¦ä¸è¶³ ({len(data)} < {actual_size})ï¼Œé‡è¯• {retry+1}")
                            time.sleep(self.retry_delay * (2 ** retry))
                            continue

                        with open(part_file, 'wb') as f:
                            f.write(data)

                        print(f"  ğŸ“¥ åˆ†ç‰‡ {i+1}/{n_chunks} âœ“")
                        success = True
                        break

                    except Exception as e:
                        print(f"  âš ï¸ åˆ†ç‰‡ {i+1} å¼‚å¸¸: {e}")
                        time.sleep(self.retry_delay * (2 ** retry))

                if not success:
                    print(f"  âŒ åˆ†ç‰‡ {i+1} ä¸‹è½½å¤±è´¥")
                    return False
                part_files.append(part_file)

            # é‡å æ ¡éªŒ
            print(f"  ğŸ” é‡å ä¸€è‡´æ€§æ£€æŸ¥...")
            for i in range(n_chunks - 1):
                with open(part_files[i], 'rb') as f1, open(part_files[i+1], 'rb') as f2:
                    f1.seek(-overlap, os.SEEK_END)
                    if f1.read(overlap) != f2.read(overlap):
                        print(f"  âŒ æ ¡éªŒå¤±è´¥ï¼šåˆ†ç‰‡ {i+1} â†” {i+2} å­—èŠ‚ä¸åŒ¹é…")
                        return False

            # åˆå¹¶æ–‡ä»¶
            print(f"  ğŸ”— åˆå¹¶åˆ†ç‰‡...")
            with open(local_tar, 'wb') as out_f:
                for i, p_file in enumerate(part_files):
                    with open(p_file, 'rb') as f:
                        if i == 0:
                            out_f.write(f.read())
                        else:
                            f.seek(overlap)
                            out_f.write(f.read())

            if os.path.getsize(local_tar) != file_size:
                print(f"  âŒ æœ€ç»ˆå¤§å°ä¸åŒ¹é…: {os.path.getsize(local_tar)} != {file_size}")
                return False
            return True

        finally:
            shutil.rmtree(temp_dir, ignore_errors=True)

    def _verify_md5(self, remote_tar: str, local_tar: str) -> bool:
        print(f"  ğŸ” æ‰§è¡Œç«¯åˆ°ç«¯ MD5 æ ¡éªŒ...")
        try:
            _, remote_md5_out, _ = self.rish_exec(f"md5sum '{remote_tar}'", timeout=60)
            remote_md5 = remote_md5_out.split()[0].strip()
        except Exception as e:
            print(f"  âš ï¸ æ— æ³•è·å–è¿œç¨‹MD5: {e}")
            return True

        local_md5 = hashlib.md5()
        with open(local_tar, 'rb') as f:
            for chunk in iter(lambda: f.read(1024 * 1024), b''):
                local_md5.update(chunk)
        
        match = (remote_md5 == local_md5.hexdigest())
        if match:
            print(f"  âœ… MD5 éªŒè¯æˆåŠŸ")
        else:
            print(f"  âŒ MD5 éªŒè¯å¤±è´¥: è¿œç¨‹ {remote_md5} vs æœ¬åœ° {local_md5.hexdigest()}")
        return match

    def _extract_tar(self, local_tar: str, uid: str, c_folder: str) -> bool:
        extract_dir = os.path.join(self.local_cache, uid)
        os.makedirs(extract_dir, exist_ok=True)
        target_dir = os.path.join(extract_dir, c_folder)
        if os.path.exists(target_dir):
            shutil.rmtree(target_dir)

        print(f"  ğŸ“‚ æ­£åœ¨è§£åŒ…è‡³: {extract_dir}")
        try:
            with tarfile.open(local_tar, 'r') as tar:
                tar.extractall(path=extract_dir)
            return True
        except Exception as e:
            print(f"  âŒ è§£åŒ…å‘ç”Ÿå¼‚å¸¸: {e}")
            return False

    def download_and_extract(self, uid: str, c_folder: str, cleanup: bool = True) -> bool:
        if self.check_local_cache(uid, c_folder):
            return True

        local_tar, remote_tar = None, None
        try:
            remote_tar, file_size = self._remote_pack(uid, c_folder)
            local_tar = os.path.join(self.local_cache or tempfile.gettempdir(), f"{uid}_{c_folder}.tar")
            
            if not self._download_chunks_overlap(remote_tar, file_size, local_tar):
                return False
            if not self._verify_md5(remote_tar, local_tar):
                return False
            if not self._extract_tar(local_tar, uid, c_folder):
                return False
            return True
        finally:
            if cleanup and remote_tar: 
                try: self.rish_exec(f"rm -f '{remote_tar}'", check=False)
                except: pass
            if local_tar and os.path.exists(local_tar): 
                try: os.remove(local_tar)
                except: pass

    def get_local_path(self, uid: str, c_folder: str) -> Optional[str]:
        path = os.path.join(self.local_cache, uid, c_folder)
        return path if os.path.exists(path) else None


# ========================== é‡è¯•åŒ…è£…ç±» ==========================
class VideoRetryPackTransfer:
    def __init__(self, pack_transfer: PackTransfer):
        self.pt = pack_transfer
        self.video_max_retries = 5        # å•ä¸ªè§†é¢‘æœ€å¤§é‡å¯æ¬¡æ•°
        self.video_retry_base_delay = 5   # åŸºç¡€é‡è¯•ç­‰å¾…ç§’æ•°

    def download_video_with_retry(self, uid: str, c_folder: str, cleanup: bool = True) -> bool:
        print(f"\n===== å¼€å§‹è§†é¢‘ä»»åŠ¡ï¼š{uid}/{c_folder} =====")
        for retry in range(1, self.video_max_retries + 1):
            try:
                ok = self.pt.download_and_extract(uid, c_folder, cleanup=cleanup)
                if ok:
                    print(f"===== âœ… è§†é¢‘ {uid}/{c_folder} å¤„ç†æˆåŠŸ =====")
                    return True
                else:
                    print(f"===== âŒ è§†é¢‘ {uid}/{c_folder} å¤„ç†å¤±è´¥ï¼Œå‡†å¤‡é‡è¯• {retry}/{self.video_max_retries} =====")
            except Exception as e:
                print(f"===== âš ï¸ è§†é¢‘ {uid}/{c_folder} å¼‚å¸¸ï¼š{e}ï¼Œé‡è¯• {retry}/{self.video_max_retries} =====")

            # æŒ‡æ•°é€€é¿
            wait = self.video_retry_base_delay * (2 ** (retry - 1))
            print(f"===== â³ ç­‰å¾… {wait}s åé‡å¯è§†é¢‘ä»»åŠ¡ =====")
            time.sleep(wait)

        print(f"===== âŒ è§†é¢‘ {uid}/{c_folder} å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä»»åŠ¡ç»ˆæ­¢ =====")
        return False


# ========================== è¾…åŠ©å‡½æ•° ==========================
def v_pack_transfer_with_retry(
    uid: str,
    c_folder: str,
    rish_exec,
    local_cache: str,
    cleanup: bool = True
) -> bool:
    pt = PackTransfer()
    pt.set_rish_executor(rish_exec)
    pt.set_local_cache(local_cache)
    
    vr = VideoRetryPackTransfer(pt)
    return vr.download_video_with_retry(uid, c_folder, cleanup=cleanup)